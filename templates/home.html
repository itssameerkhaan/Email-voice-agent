<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Agent Interface</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.8/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-sRIl4kxILFvY47J16cr9ZwB07vP4J8+LH7qKQnuqkuIAvNWLzeN8tE5YBujZqJLB" crossorigin="anonymous">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/style.css') }}">
</head>
<body>
    <div class="container-fluid p-0">
        <div class="row g-0">
            <!-- LEFT PANEL -->
            <div class="col-12 col-md-8 left-panel">
                <h1>SAMEER KHAN</h1>

                <!-- Mic Button -->
                <button class="mic-button" id="micButton">
                    <svg xmlns="http://www.w3.org/2000/svg" width="64" height="64" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                        <path d="M12 2a3 3 0 0 0-3 3v7a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3Z"/>
                        <path d="M19 10v2a7 7 0 0 1-14 0v-2"/>
                        <line x1="12" x2="12" y1="19" y2="22"/>
                    </svg>
                </button>

                <!-- Speaking Indicator (animated dots) -->
                <div class="speaking-indicator" id="speakingIndicator">
                    <span>.</span><span>.</span><span>.</span><span>.</span><span>.</span><span>.</span><span>.</span><span>.</span><span>.</span>
                </div>

                <!-- Status Message -->
                <p id="statusMessage" style="margin-top: 20px; font-size: 1.2rem;"></p>

                <!-- Response Audio Player (hidden) -->
                <div id="responseContainer" style="display: none;">
                    <audio id="responseAudio" controls autoplay>
                        <source id="responseSource" src="" type="audio/mpeg">
                        Your browser does not support the audio element.
                    </audio>
                </div>

                <!-- Menu Icon (Mobile) -->
                <div class="menu-icon" id="menuIcon">
                    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                        <line x1="4" x2="20" y1="12" y2="12"/>
                        <line x1="4" x2="20" y1="6" y2="6"/>
                        <line x1="4" x2="20" y1="18" y2="18"/>
                    </svg>
                </div>
            </div>

            <!-- RIGHT PANEL (Desktop Only) -->
            <div class="col-md-4 d-none d-md-flex right-panel">
                <div class="box">
          
                    
                    <!-- Audio List Container -->
                    <div id="audioListContainer" class="audio-list-container">
                        <p style="color: rgba(255,255,255,0.7); font-size: 1rem;">Loading recordings...</p>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile Overlay -->
    <div class="mobile-overlay" id="mobileOverlay">
        <!-- Close Icon -->
        <div class="close-icon" id="closeIcon">
            <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                <line x1="18" y1="6" x2="6" y2="18"/>
                <line x1="6" y1="6" x2="18" y2="18"/>
            </svg>
        </div>
        <div style="width: 90%; max-width: 500px;">
          
            
            <!-- Audio List Container for Mobile -->
            <div id="audioListContainerMobile" class="audio-list-container">
                <p style="color: rgba(255,255,255,0.7); font-size: 1rem;">Loading recordings...</p>
            </div>
        </div>
    </div>
    

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.8/dist/js/bootstrap.bundle.min.js" integrity="sha384-FKyoEForCGlyvwx9Hj09JcYn3nv7wiPVlz7YYwJrWVcXK/BmnVDxM+D2scQbITxI" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.8/dist/js/bootstrap.bundle.min.js" integrity="sha384-FKyoEForCGlyvwx9Hj09JcYn3nv7wiPVlz7YYwJrWVcXK/BmnVDxM+D2scQbITxI" crossorigin="anonymous"></script>
<script>
    const micButton = document.getElementById('micButton');
    const menuIcon = document.getElementById('menuIcon');
    const mobileOverlay = document.getElementById('mobileOverlay');
    const closeIcon = document.getElementById('closeIcon');
    const statusMessage = document.getElementById('statusMessage');
    const audioListContainer = document.getElementById('audioListContainer');
    const audioListContainerMobile = document.getElementById('audioListContainerMobile');
    
    let isRecording = false;
    let mediaRecorder;
    let audioChunks = [];
    let stream = null;

    // Request microphone permission immediately when page loads
    window.addEventListener('load', function() {
        requestMicrophonePermission();
        loadAudioList();
    });

    // Request microphone permission
    async function requestMicrophonePermission() {
        try {
            statusMessage.textContent = 'Requesting microphone access...';
            statusMessage.style.color = '#FFA500';
            
            stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            
            statusMessage.textContent = 'Microphone ready! Press and hold to record';
            statusMessage.style.color = '#28A745';
            
            console.log('Microphone permission granted');
            
            // Auto-hide message after 3 seconds
            setTimeout(function() {
                statusMessage.textContent = '';
            }, 3000);
            
        } catch (error) {
            console.error('Microphone permission denied:', error);
            statusMessage.textContent = 'Microphone access denied! Please allow microphone permission.';
            statusMessage.style.color = '#FF4D4D';
            
            // Show persistent error message
            micButton.disabled = true;
            micButton.style.opacity = '0.5';
            micButton.style.cursor = 'not-allowed';
        }
    }

    // Load and display audio files
    async function loadAudioList() {
        try {
            const response = await fetch('/get-audio-list');
            const data = await response.json();
            
            if (response.ok && data.files.length > 0) {
                displayAudioList(data.files);
            } else {
                audioListContainer.innerHTML = '<p style="color: rgba(255,255,255,0.7); font-size: 0.9rem;">No recordings yet</p>';
                audioListContainerMobile.innerHTML = '<p style="color: rgba(255,255,255,0.7); font-size: 0.9rem;">No recordings yet</p>';
            }
        } catch (error) {
            console.error('Error loading audio list:', error);
            audioListContainer.innerHTML = '<p style="color: rgba(255,255,255,0.7); font-size: 0.9rem;">Error loading recordings</p>';
            audioListContainerMobile.innerHTML = '<p style="color: rgba(255,255,255,0.7); font-size: 0.9rem;">Error loading recordings</p>';
        }
    }

    // Display audio list with players
    function displayAudioList(files) {
        let htmlContent = '';
        
        files.forEach(function(file, index) {
            // Extract query number and timestamp from filename
            // Format: query_1_20251022_183045.mp3
            const parts = file.replace('.mp3', '').replace('.webm', '').replace('.m4a', '').split('_');
            const queryNumber = parts[1];
            const timestamp = parts.slice(2).join('_');
            const formattedTime = formatTimestamp(timestamp);
            
            // Determine audio type
            let audioType = 'audio/mpeg';
            if (file.endsWith('.webm')) audioType = 'audio/webm';
            if (file.endsWith('.m4a')) audioType = 'audio/mp4';
            
            htmlContent += '<div class="audio-item">';
            htmlContent += '<div class="audio-info">';
            htmlContent += '<strong>Query ' + queryNumber + '</strong>';
            htmlContent += '<small>' + formattedTime + '</small>';
            htmlContent += '</div>';
            htmlContent += '<audio controls class="audio-player">';
            htmlContent += '<source src="/audio/' + file + '" type="' + audioType + '">';
            htmlContent += 'Your browser does not support the audio element.';
            htmlContent += '</audio>';
            htmlContent += '</div>';
        });
        
        audioListContainer.innerHTML = htmlContent;
        audioListContainerMobile.innerHTML = htmlContent;
    }
    // Format timestamp for display
    function formatTimestamp(timestamp) {
        // timestamp format: YYYYMMDD_HHMMSS
        const year = timestamp.substring(0, 4);
        const month = timestamp.substring(4, 6);
        const day = timestamp.substring(6, 8);
        const hour = timestamp.substring(9, 11);
        const minute = timestamp.substring(11, 13);
        const second = timestamp.substring(13, 15);
        
        return day + '/' + month + '/' + year + ' ' + hour + ':' + minute + ':' + second;
    }

    // Start recording
    async function startRecording() {
        if (isRecording) return;
        
        // If stream is not available, request permission again
        if (!stream) {
            await requestMicrophonePermission();
            if (!stream) return;
        }
        
        isRecording = true;
        micButton.classList.add('recording');
        audioChunks = [];
        statusMessage.textContent = 'Listening  ...';
        statusMessage.style.color = '#FF4D4D';
        
        try {
            // Get fresh stream for recording
            const recordStream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(recordStream);
            
            mediaRecorder.ondataavailable = function(event) {
                if (event.data.size > 0) {
                    audioChunks.push(event.data);
                }
            };
            
            mediaRecorder.onstop = async function() {
                const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                await saveAudio(audioBlob);
                
                // Stop all audio tracks
                recordStream.getTracks().forEach(function(track) {
                    track.stop();
                });
            };
            
            mediaRecorder.start();
            console.log('Recording started');
        } catch (error) {
            console.error('Error starting recording:', error);
            statusMessage.textContent = 'Error: ' + error.message;
            statusMessage.style.color = '#FF4D4D';
            isRecording = false;
            micButton.classList.remove('recording');
        }
    }

    // Stop recording
    function stopRecording() {
        if (!isRecording) return;
        
        isRecording = false;
        micButton.classList.remove('recording');
        statusMessage.textContent = 'Saving...';
        
        if (mediaRecorder && mediaRecorder.state !== 'inactive') {
            mediaRecorder.stop();
            console.log('Recording stopped');
        }
    }

    // Save audio to server
    async function saveAudio(audioBlob) {
        const formData = new FormData();
        
        // Check blob type and append appropriate file
        console.log('Audio blob type:', audioBlob.type);
        console.log('Audio blob size:', audioBlob.size);
        
        if (audioBlob.size === 0) {
            statusMessage.textContent = 'Error: Empty recording';
            statusMessage.style.color = '#FF4D4D';
            return;
        }
        
        formData.append('audio', audioBlob, 'recording.webm');
        
        try {
            statusMessage.textContent = 'Uploading...';
            
            const response = await fetch('/save-audio', {
                method: 'POST',
                body: formData
            });
            
            const result = await response.json();
            
            if (response.ok) {
                statusMessage.textContent = 'Audio saved: ' + result.filename;
                statusMessage.style.color = '#28A745';
                console.log('Audio saved successfully:', result.filename);
                
                // Reload audio list to show new recording
                setTimeout(function() {
                    loadAudioList();
                    statusMessage.textContent = '';
                }, 2000);
            } else {
                statusMessage.textContent = 'Error: ' + result.error;
                statusMessage.style.color = '#FF4D4D';
                console.error('Server error:', result.error);
            }
        } catch (error) {
            statusMessage.textContent = 'Upload failed: ' + error.message;
            statusMessage.style.color = '#FF4D4D';
            console.error('Upload error:', error);
        }
    }

    // Mouse events
    micButton.addEventListener('mousedown', startRecording);
    micButton.addEventListener('mouseup', stopRecording);
    micButton.addEventListener('mouseleave', stopRecording);

    // Touch events
    micButton.addEventListener('touchstart', function(e) {
        e.preventDefault();
        startRecording();
    });

    micButton.addEventListener('touchend', function(e) {
        e.preventDefault();
        stopRecording();
    });

    // Mobile menu - open
    menuIcon.addEventListener('click', function() {
        mobileOverlay.classList.add('show');
    });

    // Mobile menu - close
    closeIcon.addEventListener('click', function(e) {
        e.stopPropagation();
        mobileOverlay.classList.remove('show');
    });


    let lastResponseTimestamp = 0;
    let isCheckingResponse = false;

    // Check for response audio periodically
    function checkForResponse() {
        if (isCheckingResponse) return;
        
        fetch('/check-response')
            .then(function(response) { return response.json(); })
            .then(function(data) {
                if (data.available && data.timestamp > lastResponseTimestamp) {
                    // New response available
                    lastResponseTimestamp = data.timestamp;
                    playResponseAudio();
                }
            })
            .catch(function(error) {
                console.error('Error checking response:', error);
            });
    }

    // Play the response audio with animation
    function playResponseAudio() {
        const responseContainer = document.getElementById('responseContainer');
        const responseAudio = document.getElementById('responseAudio');
        const responseSource = document.getElementById('responseSource');
        const speakingIndicator = document.getElementById('speakingIndicator');
        
        // Show speaking indicator
        speakingIndicator.classList.add('active');
        statusMessage.textContent = 'Speaking...';
        statusMessage.style.color = '#FFA500';
        
        // Update source with timestamp to prevent caching
        responseSource.src = '/get-response?t=' + Date.now();
        responseAudio.load();
        
        // Show the audio player (optional, if you want to show controls)
        responseContainer.style.display = 'block';
        
        // Auto-play the response
        responseAudio.play()
            .then(function() {
                console.log('Audio playing successfully');
            })
            .catch(function(error) {
                console.log('Auto-play prevented:', error);
                // If autoplay fails, show message to user
                statusMessage.textContent = 'Click to play response';
                statusMessage.style.color = '#28A745';
                speakingIndicator.classList.remove('active');
            });
        
        // When audio ends, hide the indicator
        responseAudio.onended = function() {
            speakingIndicator.classList.remove('active');
            statusMessage.textContent = '';
            // Optionally hide the audio player
            // responseContainer.style.display = 'none';
        };
        
        // When audio starts playing
        responseAudio.onplay = function() {
            speakingIndicator.classList.add('active');
            statusMessage.textContent = 'Speaking...';
            statusMessage.style.color = '#FFA500';
        };
        
        // When audio is paused
        responseAudio.onpause = function() {
            speakingIndicator.classList.remove('active');
            statusMessage.textContent = '';
        };
    }

    // Start checking for responses every 2 seconds
    // Allow future autoplay after one user interaction
    document.addEventListener('click', function enableAudioPlayback() {
        const audio = document.getElementById('responseAudio');
        audio.play().catch(() => {});
        audio.pause();
        document.removeEventListener('click', enableAudioPlayback);
        console.log('Autoplay unlocked after user interaction');
    });
    setInterval(checkForResponse, 500);
</script>
</body>
</html>